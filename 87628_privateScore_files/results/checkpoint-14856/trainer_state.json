{
  "best_global_step": 14856,
  "best_metric": 0.9263636363636364,
  "best_model_checkpoint": "./results/checkpoint-14856",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 14856,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.053850296176628974,
      "grad_norm": 0.9539346098899841,
      "learning_rate": 8.972633467922837e-07,
      "loss": 1.3916,
      "step": 100
    },
    {
      "epoch": 0.10770059235325795,
      "grad_norm": 1.2846683263778687,
      "learning_rate": 1.7945266935845674e-06,
      "loss": 1.3905,
      "step": 200
    },
    {
      "epoch": 0.16155088852988692,
      "grad_norm": 1.5296052694320679,
      "learning_rate": 2.691790040376851e-06,
      "loss": 1.3859,
      "step": 300
    },
    {
      "epoch": 0.2154011847065159,
      "grad_norm": 1.8940387964248657,
      "learning_rate": 3.5890533871691348e-06,
      "loss": 1.3795,
      "step": 400
    },
    {
      "epoch": 0.2692514808831449,
      "grad_norm": 1.2180910110473633,
      "learning_rate": 4.486316733961418e-06,
      "loss": 1.37,
      "step": 500
    },
    {
      "epoch": 0.32310177705977383,
      "grad_norm": 1.6248213052749634,
      "learning_rate": 5.383580080753702e-06,
      "loss": 1.324,
      "step": 600
    },
    {
      "epoch": 0.3769520732364028,
      "grad_norm": 2.6777870655059814,
      "learning_rate": 6.280843427545985e-06,
      "loss": 1.0097,
      "step": 700
    },
    {
      "epoch": 0.4308023694130318,
      "grad_norm": 3.2101731300354004,
      "learning_rate": 7.1781067743382695e-06,
      "loss": 0.5595,
      "step": 800
    },
    {
      "epoch": 0.48465266558966075,
      "grad_norm": 4.356380939483643,
      "learning_rate": 8.075370121130552e-06,
      "loss": 0.3999,
      "step": 900
    },
    {
      "epoch": 0.5385029617662898,
      "grad_norm": 6.0082526206970215,
      "learning_rate": 8.972633467922836e-06,
      "loss": 0.3717,
      "step": 1000
    },
    {
      "epoch": 0.5923532579429187,
      "grad_norm": 4.237320899963379,
      "learning_rate": 9.86989681471512e-06,
      "loss": 0.3496,
      "step": 1100
    },
    {
      "epoch": 0.6462035541195477,
      "grad_norm": 2.307737350463867,
      "learning_rate": 1.0767160161507404e-05,
      "loss": 0.3541,
      "step": 1200
    },
    {
      "epoch": 0.7000538502961766,
      "grad_norm": 4.674252986907959,
      "learning_rate": 1.1664423508299687e-05,
      "loss": 0.3565,
      "step": 1300
    },
    {
      "epoch": 0.7539041464728056,
      "grad_norm": 3.94592022895813,
      "learning_rate": 1.256168685509197e-05,
      "loss": 0.3333,
      "step": 1400
    },
    {
      "epoch": 0.8077544426494345,
      "grad_norm": 6.688425064086914,
      "learning_rate": 1.3458950201884253e-05,
      "loss": 0.3283,
      "step": 1500
    },
    {
      "epoch": 0.8616047388260636,
      "grad_norm": 3.6313507556915283,
      "learning_rate": 1.4356213548676539e-05,
      "loss": 0.3203,
      "step": 1600
    },
    {
      "epoch": 0.9154550350026925,
      "grad_norm": 4.078710079193115,
      "learning_rate": 1.5253476895468822e-05,
      "loss": 0.3212,
      "step": 1700
    },
    {
      "epoch": 0.9693053311793215,
      "grad_norm": 9.087119102478027,
      "learning_rate": 1.6150740242261103e-05,
      "loss": 0.3082,
      "step": 1800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8977272727272727,
      "eval_loss": 0.30288684368133545,
      "eval_runtime": 21.9183,
      "eval_samples_per_second": 602.238,
      "eval_steps_per_second": 2.372,
      "step": 1857
    },
    {
      "epoch": 1.0231556273559506,
      "grad_norm": 11.117918014526367,
      "learning_rate": 1.7048003589053388e-05,
      "loss": 0.3164,
      "step": 1900
    },
    {
      "epoch": 1.0770059235325795,
      "grad_norm": 3.702152729034424,
      "learning_rate": 1.7945266935845673e-05,
      "loss": 0.3114,
      "step": 2000
    },
    {
      "epoch": 1.1308562197092085,
      "grad_norm": 6.52518367767334,
      "learning_rate": 1.8842530282637957e-05,
      "loss": 0.3197,
      "step": 2100
    },
    {
      "epoch": 1.1847065158858374,
      "grad_norm": 7.937997341156006,
      "learning_rate": 1.973979362943024e-05,
      "loss": 0.2986,
      "step": 2200
    },
    {
      "epoch": 1.2385568120624664,
      "grad_norm": 7.072605609893799,
      "learning_rate": 1.9929194714535028e-05,
      "loss": 0.3037,
      "step": 2300
    },
    {
      "epoch": 1.2924071082390953,
      "grad_norm": 4.801469326019287,
      "learning_rate": 1.9829468960359016e-05,
      "loss": 0.2995,
      "step": 2400
    },
    {
      "epoch": 1.3462574044157243,
      "grad_norm": 5.262712478637695,
      "learning_rate": 1.9729743206182998e-05,
      "loss": 0.2885,
      "step": 2500
    },
    {
      "epoch": 1.4001077005923532,
      "grad_norm": 5.260756015777588,
      "learning_rate": 1.9630017452006982e-05,
      "loss": 0.2992,
      "step": 2600
    },
    {
      "epoch": 1.4539579967689822,
      "grad_norm": 4.1954345703125,
      "learning_rate": 1.9530291697830964e-05,
      "loss": 0.2983,
      "step": 2700
    },
    {
      "epoch": 1.5078082929456111,
      "grad_norm": 7.4740777015686035,
      "learning_rate": 1.9430565943654952e-05,
      "loss": 0.2793,
      "step": 2800
    },
    {
      "epoch": 1.5616585891222403,
      "grad_norm": 4.461886405944824,
      "learning_rate": 1.9330840189478933e-05,
      "loss": 0.279,
      "step": 2900
    },
    {
      "epoch": 1.615508885298869,
      "grad_norm": 11.247560501098633,
      "learning_rate": 1.9231114435302918e-05,
      "loss": 0.2843,
      "step": 3000
    },
    {
      "epoch": 1.6693591814754982,
      "grad_norm": 5.754551887512207,
      "learning_rate": 1.9131388681126903e-05,
      "loss": 0.2734,
      "step": 3100
    },
    {
      "epoch": 1.723209477652127,
      "grad_norm": 5.808860778808594,
      "learning_rate": 1.9031662926950887e-05,
      "loss": 0.286,
      "step": 3200
    },
    {
      "epoch": 1.7770597738287561,
      "grad_norm": 9.032245635986328,
      "learning_rate": 1.893193717277487e-05,
      "loss": 0.2762,
      "step": 3300
    },
    {
      "epoch": 1.830910070005385,
      "grad_norm": 5.213246822357178,
      "learning_rate": 1.8832211418598854e-05,
      "loss": 0.2851,
      "step": 3400
    },
    {
      "epoch": 1.884760366182014,
      "grad_norm": 6.365306854248047,
      "learning_rate": 1.873248566442284e-05,
      "loss": 0.2765,
      "step": 3500
    },
    {
      "epoch": 1.938610662358643,
      "grad_norm": 3.390352487564087,
      "learning_rate": 1.8632759910246823e-05,
      "loss": 0.2857,
      "step": 3600
    },
    {
      "epoch": 1.992460958535272,
      "grad_norm": 4.962512016296387,
      "learning_rate": 1.8533034156070804e-05,
      "loss": 0.2865,
      "step": 3700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9094696969696969,
      "eval_loss": 0.2628578245639801,
      "eval_runtime": 21.9178,
      "eval_samples_per_second": 602.249,
      "eval_steps_per_second": 2.372,
      "step": 3714
    },
    {
      "epoch": 2.046311254711901,
      "grad_norm": 4.339007377624512,
      "learning_rate": 1.8433308401894793e-05,
      "loss": 0.2717,
      "step": 3800
    },
    {
      "epoch": 2.10016155088853,
      "grad_norm": 5.0328521728515625,
      "learning_rate": 1.8333582647718774e-05,
      "loss": 0.2721,
      "step": 3900
    },
    {
      "epoch": 2.154011847065159,
      "grad_norm": 5.3656439781188965,
      "learning_rate": 1.823385689354276e-05,
      "loss": 0.2736,
      "step": 4000
    },
    {
      "epoch": 2.2078621432417878,
      "grad_norm": 5.013122081756592,
      "learning_rate": 1.8134131139366743e-05,
      "loss": 0.2808,
      "step": 4100
    },
    {
      "epoch": 2.261712439418417,
      "grad_norm": 7.151144027709961,
      "learning_rate": 1.8034405385190728e-05,
      "loss": 0.2654,
      "step": 4200
    },
    {
      "epoch": 2.3155627355950457,
      "grad_norm": 4.904406547546387,
      "learning_rate": 1.793467963101471e-05,
      "loss": 0.2636,
      "step": 4300
    },
    {
      "epoch": 2.369413031771675,
      "grad_norm": 4.979892730712891,
      "learning_rate": 1.7834953876838694e-05,
      "loss": 0.2685,
      "step": 4400
    },
    {
      "epoch": 2.4232633279483036,
      "grad_norm": 4.11600923538208,
      "learning_rate": 1.773522812266268e-05,
      "loss": 0.2533,
      "step": 4500
    },
    {
      "epoch": 2.4771136241249327,
      "grad_norm": 5.05602502822876,
      "learning_rate": 1.7635502368486664e-05,
      "loss": 0.2662,
      "step": 4600
    },
    {
      "epoch": 2.530963920301562,
      "grad_norm": 5.877993106842041,
      "learning_rate": 1.7535776614310645e-05,
      "loss": 0.2691,
      "step": 4700
    },
    {
      "epoch": 2.5848142164781907,
      "grad_norm": 4.774616241455078,
      "learning_rate": 1.743605086013463e-05,
      "loss": 0.2692,
      "step": 4800
    },
    {
      "epoch": 2.6386645126548194,
      "grad_norm": 6.607170104980469,
      "learning_rate": 1.7336325105958615e-05,
      "loss": 0.2551,
      "step": 4900
    },
    {
      "epoch": 2.6925148088314486,
      "grad_norm": 6.130038738250732,
      "learning_rate": 1.72365993517826e-05,
      "loss": 0.2531,
      "step": 5000
    },
    {
      "epoch": 2.7463651050080777,
      "grad_norm": 5.473919868469238,
      "learning_rate": 1.7136873597606584e-05,
      "loss": 0.2693,
      "step": 5100
    },
    {
      "epoch": 2.8002154011847065,
      "grad_norm": 11.229957580566406,
      "learning_rate": 1.703714784343057e-05,
      "loss": 0.2681,
      "step": 5200
    },
    {
      "epoch": 2.8540656973613356,
      "grad_norm": 4.716215133666992,
      "learning_rate": 1.693742208925455e-05,
      "loss": 0.2563,
      "step": 5300
    },
    {
      "epoch": 2.9079159935379644,
      "grad_norm": 8.197209358215332,
      "learning_rate": 1.6837696335078535e-05,
      "loss": 0.2412,
      "step": 5400
    },
    {
      "epoch": 2.9617662897145935,
      "grad_norm": 8.152640342712402,
      "learning_rate": 1.673797058090252e-05,
      "loss": 0.252,
      "step": 5500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9135606060606061,
      "eval_loss": 0.24196603894233704,
      "eval_runtime": 21.8868,
      "eval_samples_per_second": 603.104,
      "eval_steps_per_second": 2.376,
      "step": 5571
    },
    {
      "epoch": 3.0156165858912223,
      "grad_norm": 5.587896823883057,
      "learning_rate": 1.6638244826726504e-05,
      "loss": 0.2605,
      "step": 5600
    },
    {
      "epoch": 3.0694668820678515,
      "grad_norm": 6.11496639251709,
      "learning_rate": 1.6538519072550486e-05,
      "loss": 0.245,
      "step": 5700
    },
    {
      "epoch": 3.12331717824448,
      "grad_norm": 3.7689096927642822,
      "learning_rate": 1.643879331837447e-05,
      "loss": 0.2385,
      "step": 5800
    },
    {
      "epoch": 3.1771674744211094,
      "grad_norm": 8.645294189453125,
      "learning_rate": 1.6339067564198455e-05,
      "loss": 0.25,
      "step": 5900
    },
    {
      "epoch": 3.231017770597738,
      "grad_norm": 8.127867698669434,
      "learning_rate": 1.623934181002244e-05,
      "loss": 0.2516,
      "step": 6000
    },
    {
      "epoch": 3.2848680667743673,
      "grad_norm": 9.590459823608398,
      "learning_rate": 1.6139616055846425e-05,
      "loss": 0.2452,
      "step": 6100
    },
    {
      "epoch": 3.3387183629509964,
      "grad_norm": 5.498569965362549,
      "learning_rate": 1.6039890301670406e-05,
      "loss": 0.2561,
      "step": 6200
    },
    {
      "epoch": 3.392568659127625,
      "grad_norm": 7.960572719573975,
      "learning_rate": 1.594016454749439e-05,
      "loss": 0.2486,
      "step": 6300
    },
    {
      "epoch": 3.4464189553042544,
      "grad_norm": 5.416164875030518,
      "learning_rate": 1.5840438793318376e-05,
      "loss": 0.2542,
      "step": 6400
    },
    {
      "epoch": 3.500269251480883,
      "grad_norm": 7.868542671203613,
      "learning_rate": 1.574071303914236e-05,
      "loss": 0.2262,
      "step": 6500
    },
    {
      "epoch": 3.5541195476575123,
      "grad_norm": 6.368574142456055,
      "learning_rate": 1.5640987284966345e-05,
      "loss": 0.2393,
      "step": 6600
    },
    {
      "epoch": 3.607969843834141,
      "grad_norm": 10.630818367004395,
      "learning_rate": 1.5541261530790326e-05,
      "loss": 0.2488,
      "step": 6700
    },
    {
      "epoch": 3.66182014001077,
      "grad_norm": 4.074277877807617,
      "learning_rate": 1.544153577661431e-05,
      "loss": 0.2452,
      "step": 6800
    },
    {
      "epoch": 3.715670436187399,
      "grad_norm": 8.021141052246094,
      "learning_rate": 1.5341810022438296e-05,
      "loss": 0.2418,
      "step": 6900
    },
    {
      "epoch": 3.769520732364028,
      "grad_norm": 4.972331523895264,
      "learning_rate": 1.524208426826228e-05,
      "loss": 0.2434,
      "step": 7000
    },
    {
      "epoch": 3.823371028540657,
      "grad_norm": 6.675139427185059,
      "learning_rate": 1.5142358514086264e-05,
      "loss": 0.2433,
      "step": 7100
    },
    {
      "epoch": 3.877221324717286,
      "grad_norm": 6.234257221221924,
      "learning_rate": 1.5042632759910247e-05,
      "loss": 0.2245,
      "step": 7200
    },
    {
      "epoch": 3.931071620893915,
      "grad_norm": 4.3092522621154785,
      "learning_rate": 1.4942907005734233e-05,
      "loss": 0.2416,
      "step": 7300
    },
    {
      "epoch": 3.984921917070544,
      "grad_norm": 3.8075525760650635,
      "learning_rate": 1.4843181251558216e-05,
      "loss": 0.2393,
      "step": 7400
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9206818181818182,
      "eval_loss": 0.22627222537994385,
      "eval_runtime": 21.8165,
      "eval_samples_per_second": 605.048,
      "eval_steps_per_second": 2.384,
      "step": 7428
    },
    {
      "epoch": 4.038772213247173,
      "grad_norm": 5.243251323699951,
      "learning_rate": 1.47434554973822e-05,
      "loss": 0.2249,
      "step": 7500
    },
    {
      "epoch": 4.092622509423802,
      "grad_norm": 7.104671001434326,
      "learning_rate": 1.4643729743206182e-05,
      "loss": 0.2264,
      "step": 7600
    },
    {
      "epoch": 4.146472805600431,
      "grad_norm": 4.901620388031006,
      "learning_rate": 1.4544003989030169e-05,
      "loss": 0.2371,
      "step": 7700
    },
    {
      "epoch": 4.20032310177706,
      "grad_norm": 11.72463607788086,
      "learning_rate": 1.4444278234854152e-05,
      "loss": 0.2252,
      "step": 7800
    },
    {
      "epoch": 4.254173397953688,
      "grad_norm": 7.29785680770874,
      "learning_rate": 1.4344552480678135e-05,
      "loss": 0.226,
      "step": 7900
    },
    {
      "epoch": 4.308023694130318,
      "grad_norm": 4.6643147468566895,
      "learning_rate": 1.4244826726502121e-05,
      "loss": 0.2374,
      "step": 8000
    },
    {
      "epoch": 4.361873990306947,
      "grad_norm": 4.356359481811523,
      "learning_rate": 1.4145100972326104e-05,
      "loss": 0.2351,
      "step": 8100
    },
    {
      "epoch": 4.4157242864835755,
      "grad_norm": 3.3185017108917236,
      "learning_rate": 1.4045375218150087e-05,
      "loss": 0.2289,
      "step": 8200
    },
    {
      "epoch": 4.469574582660204,
      "grad_norm": 6.693193435668945,
      "learning_rate": 1.3945649463974072e-05,
      "loss": 0.2295,
      "step": 8300
    },
    {
      "epoch": 4.523424878836834,
      "grad_norm": 4.972700595855713,
      "learning_rate": 1.3845923709798057e-05,
      "loss": 0.2277,
      "step": 8400
    },
    {
      "epoch": 4.577275175013463,
      "grad_norm": 3.5598554611206055,
      "learning_rate": 1.374619795562204e-05,
      "loss": 0.2305,
      "step": 8500
    },
    {
      "epoch": 4.631125471190091,
      "grad_norm": 3.2750444412231445,
      "learning_rate": 1.3646472201446023e-05,
      "loss": 0.2335,
      "step": 8600
    },
    {
      "epoch": 4.684975767366721,
      "grad_norm": 5.033941745758057,
      "learning_rate": 1.354674644727001e-05,
      "loss": 0.2291,
      "step": 8700
    },
    {
      "epoch": 4.73882606354335,
      "grad_norm": 3.593677520751953,
      "learning_rate": 1.3447020693093992e-05,
      "loss": 0.2225,
      "step": 8800
    },
    {
      "epoch": 4.792676359719978,
      "grad_norm": 4.312649726867676,
      "learning_rate": 1.3347294938917975e-05,
      "loss": 0.2346,
      "step": 8900
    },
    {
      "epoch": 4.846526655896607,
      "grad_norm": 5.005448818206787,
      "learning_rate": 1.324756918474196e-05,
      "loss": 0.2307,
      "step": 9000
    },
    {
      "epoch": 4.900376952073237,
      "grad_norm": 3.6771843433380127,
      "learning_rate": 1.3147843430565945e-05,
      "loss": 0.2252,
      "step": 9100
    },
    {
      "epoch": 4.9542272482498655,
      "grad_norm": 6.6351141929626465,
      "learning_rate": 1.3048117676389928e-05,
      "loss": 0.2292,
      "step": 9200
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9220454545454545,
      "eval_loss": 0.2213113009929657,
      "eval_runtime": 21.8258,
      "eval_samples_per_second": 604.79,
      "eval_steps_per_second": 2.383,
      "step": 9285
    },
    {
      "epoch": 5.008077544426494,
      "grad_norm": 3.632526159286499,
      "learning_rate": 1.2948391922213913e-05,
      "loss": 0.24,
      "step": 9300
    },
    {
      "epoch": 5.061927840603123,
      "grad_norm": 5.109704494476318,
      "learning_rate": 1.2848666168037898e-05,
      "loss": 0.2279,
      "step": 9400
    },
    {
      "epoch": 5.115778136779753,
      "grad_norm": 6.77773380279541,
      "learning_rate": 1.274894041386188e-05,
      "loss": 0.2203,
      "step": 9500
    },
    {
      "epoch": 5.169628432956381,
      "grad_norm": 6.032994270324707,
      "learning_rate": 1.2649214659685865e-05,
      "loss": 0.225,
      "step": 9600
    },
    {
      "epoch": 5.22347872913301,
      "grad_norm": 6.646341323852539,
      "learning_rate": 1.2549488905509848e-05,
      "loss": 0.2329,
      "step": 9700
    },
    {
      "epoch": 5.277329025309639,
      "grad_norm": 6.644493103027344,
      "learning_rate": 1.2449763151333833e-05,
      "loss": 0.2169,
      "step": 9800
    },
    {
      "epoch": 5.331179321486268,
      "grad_norm": 6.514358043670654,
      "learning_rate": 1.2350037397157816e-05,
      "loss": 0.2143,
      "step": 9900
    },
    {
      "epoch": 5.385029617662897,
      "grad_norm": 8.84879207611084,
      "learning_rate": 1.2250311642981801e-05,
      "loss": 0.217,
      "step": 10000
    },
    {
      "epoch": 5.438879913839526,
      "grad_norm": 5.9745259284973145,
      "learning_rate": 1.2150585888805786e-05,
      "loss": 0.2182,
      "step": 10100
    },
    {
      "epoch": 5.4927302100161555,
      "grad_norm": 3.594120502471924,
      "learning_rate": 1.2050860134629769e-05,
      "loss": 0.2233,
      "step": 10200
    },
    {
      "epoch": 5.546580506192784,
      "grad_norm": 2.8852012157440186,
      "learning_rate": 1.1951134380453753e-05,
      "loss": 0.2189,
      "step": 10300
    },
    {
      "epoch": 5.600430802369413,
      "grad_norm": 5.632214069366455,
      "learning_rate": 1.1851408626277736e-05,
      "loss": 0.2218,
      "step": 10400
    },
    {
      "epoch": 5.654281098546042,
      "grad_norm": 5.190887928009033,
      "learning_rate": 1.1751682872101721e-05,
      "loss": 0.2276,
      "step": 10500
    },
    {
      "epoch": 5.708131394722671,
      "grad_norm": 9.086536407470703,
      "learning_rate": 1.1651957117925706e-05,
      "loss": 0.2213,
      "step": 10600
    },
    {
      "epoch": 5.7619816908993,
      "grad_norm": 3.3467767238616943,
      "learning_rate": 1.1552231363749689e-05,
      "loss": 0.2257,
      "step": 10700
    },
    {
      "epoch": 5.815831987075929,
      "grad_norm": 4.3479743003845215,
      "learning_rate": 1.1452505609573674e-05,
      "loss": 0.2376,
      "step": 10800
    },
    {
      "epoch": 5.869682283252558,
      "grad_norm": 5.107371807098389,
      "learning_rate": 1.1352779855397657e-05,
      "loss": 0.221,
      "step": 10900
    },
    {
      "epoch": 5.923532579429187,
      "grad_norm": 4.524885177612305,
      "learning_rate": 1.1253054101221642e-05,
      "loss": 0.2243,
      "step": 11000
    },
    {
      "epoch": 5.977382875605816,
      "grad_norm": 8.26962947845459,
      "learning_rate": 1.1153328347045625e-05,
      "loss": 0.2158,
      "step": 11100
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9240151515151516,
      "eval_loss": 0.21481330692768097,
      "eval_runtime": 21.8721,
      "eval_samples_per_second": 603.508,
      "eval_steps_per_second": 2.377,
      "step": 11142
    },
    {
      "epoch": 6.031233171782445,
      "grad_norm": 6.175590515136719,
      "learning_rate": 1.105360259286961e-05,
      "loss": 0.2174,
      "step": 11200
    },
    {
      "epoch": 6.085083467959074,
      "grad_norm": 2.359159469604492,
      "learning_rate": 1.0953876838693594e-05,
      "loss": 0.2237,
      "step": 11300
    },
    {
      "epoch": 6.138933764135703,
      "grad_norm": 4.53130578994751,
      "learning_rate": 1.0854151084517577e-05,
      "loss": 0.2122,
      "step": 11400
    },
    {
      "epoch": 6.192784060312332,
      "grad_norm": 5.732298374176025,
      "learning_rate": 1.0754425330341562e-05,
      "loss": 0.2127,
      "step": 11500
    },
    {
      "epoch": 6.24663435648896,
      "grad_norm": 4.03863000869751,
      "learning_rate": 1.0654699576165547e-05,
      "loss": 0.2211,
      "step": 11600
    },
    {
      "epoch": 6.30048465266559,
      "grad_norm": 5.884408950805664,
      "learning_rate": 1.055497382198953e-05,
      "loss": 0.2258,
      "step": 11700
    },
    {
      "epoch": 6.354334948842219,
      "grad_norm": 4.272099494934082,
      "learning_rate": 1.0455248067813513e-05,
      "loss": 0.2236,
      "step": 11800
    },
    {
      "epoch": 6.4081852450188475,
      "grad_norm": 7.092421531677246,
      "learning_rate": 1.0355522313637497e-05,
      "loss": 0.2174,
      "step": 11900
    },
    {
      "epoch": 6.462035541195476,
      "grad_norm": 8.047876358032227,
      "learning_rate": 1.0255796559461482e-05,
      "loss": 0.2217,
      "step": 12000
    },
    {
      "epoch": 6.515885837372106,
      "grad_norm": 5.157403469085693,
      "learning_rate": 1.0156070805285465e-05,
      "loss": 0.2266,
      "step": 12100
    },
    {
      "epoch": 6.5697361335487345,
      "grad_norm": 9.014312744140625,
      "learning_rate": 1.005634505110945e-05,
      "loss": 0.2064,
      "step": 12200
    },
    {
      "epoch": 6.623586429725363,
      "grad_norm": 5.663997173309326,
      "learning_rate": 9.956619296933435e-06,
      "loss": 0.2214,
      "step": 12300
    },
    {
      "epoch": 6.677436725901993,
      "grad_norm": 6.571619510650635,
      "learning_rate": 9.856893542757418e-06,
      "loss": 0.2117,
      "step": 12400
    },
    {
      "epoch": 6.731287022078622,
      "grad_norm": 11.082841873168945,
      "learning_rate": 9.757167788581403e-06,
      "loss": 0.2133,
      "step": 12500
    },
    {
      "epoch": 6.78513731825525,
      "grad_norm": 3.7200818061828613,
      "learning_rate": 9.657442034405387e-06,
      "loss": 0.2113,
      "step": 12600
    },
    {
      "epoch": 6.838987614431879,
      "grad_norm": 5.787879467010498,
      "learning_rate": 9.55771628022937e-06,
      "loss": 0.2189,
      "step": 12700
    },
    {
      "epoch": 6.892837910608509,
      "grad_norm": 5.091705322265625,
      "learning_rate": 9.457990526053355e-06,
      "loss": 0.2085,
      "step": 12800
    },
    {
      "epoch": 6.946688206785137,
      "grad_norm": 4.144968509674072,
      "learning_rate": 9.358264771877338e-06,
      "loss": 0.2157,
      "step": 12900
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9252272727272727,
      "eval_loss": 0.21112123131752014,
      "eval_runtime": 21.787,
      "eval_samples_per_second": 605.866,
      "eval_steps_per_second": 2.387,
      "step": 12999
    },
    {
      "epoch": 7.000538502961766,
      "grad_norm": 7.32485818862915,
      "learning_rate": 9.258539017701323e-06,
      "loss": 0.2226,
      "step": 13000
    },
    {
      "epoch": 7.054388799138395,
      "grad_norm": 6.311959743499756,
      "learning_rate": 9.158813263525306e-06,
      "loss": 0.2035,
      "step": 13100
    },
    {
      "epoch": 7.1082390953150245,
      "grad_norm": 4.8546319007873535,
      "learning_rate": 9.05908750934929e-06,
      "loss": 0.2136,
      "step": 13200
    },
    {
      "epoch": 7.162089391491653,
      "grad_norm": 6.049841403961182,
      "learning_rate": 8.959361755173275e-06,
      "loss": 0.2069,
      "step": 13300
    },
    {
      "epoch": 7.215939687668282,
      "grad_norm": 5.725005626678467,
      "learning_rate": 8.859636000997258e-06,
      "loss": 0.2104,
      "step": 13400
    },
    {
      "epoch": 7.269789983844911,
      "grad_norm": 4.95634651184082,
      "learning_rate": 8.759910246821243e-06,
      "loss": 0.2168,
      "step": 13500
    },
    {
      "epoch": 7.32364028002154,
      "grad_norm": 4.437618732452393,
      "learning_rate": 8.660184492645226e-06,
      "loss": 0.2179,
      "step": 13600
    },
    {
      "epoch": 7.377490576198169,
      "grad_norm": 8.170467376708984,
      "learning_rate": 8.560458738469211e-06,
      "loss": 0.2117,
      "step": 13700
    },
    {
      "epoch": 7.431340872374798,
      "grad_norm": 7.459080696105957,
      "learning_rate": 8.460732984293194e-06,
      "loss": 0.2258,
      "step": 13800
    },
    {
      "epoch": 7.485191168551427,
      "grad_norm": 6.611063480377197,
      "learning_rate": 8.361007230117179e-06,
      "loss": 0.2057,
      "step": 13900
    },
    {
      "epoch": 7.539041464728056,
      "grad_norm": 6.069068908691406,
      "learning_rate": 8.261281475941164e-06,
      "loss": 0.208,
      "step": 14000
    },
    {
      "epoch": 7.592891760904685,
      "grad_norm": 4.642059803009033,
      "learning_rate": 8.161555721765147e-06,
      "loss": 0.216,
      "step": 14100
    },
    {
      "epoch": 7.646742057081314,
      "grad_norm": 5.138727188110352,
      "learning_rate": 8.061829967589131e-06,
      "loss": 0.2162,
      "step": 14200
    },
    {
      "epoch": 7.700592353257943,
      "grad_norm": 4.505308151245117,
      "learning_rate": 7.962104213413114e-06,
      "loss": 0.2088,
      "step": 14300
    },
    {
      "epoch": 7.754442649434572,
      "grad_norm": 9.364027976989746,
      "learning_rate": 7.862378459237099e-06,
      "loss": 0.212,
      "step": 14400
    },
    {
      "epoch": 7.808292945611201,
      "grad_norm": 3.843006134033203,
      "learning_rate": 7.762652705061082e-06,
      "loss": 0.2172,
      "step": 14500
    },
    {
      "epoch": 7.86214324178783,
      "grad_norm": 5.095552444458008,
      "learning_rate": 7.662926950885067e-06,
      "loss": 0.1988,
      "step": 14600
    },
    {
      "epoch": 7.915993537964459,
      "grad_norm": 4.900586128234863,
      "learning_rate": 7.563201196709052e-06,
      "loss": 0.2296,
      "step": 14700
    },
    {
      "epoch": 7.969843834141088,
      "grad_norm": 5.124968528747559,
      "learning_rate": 7.463475442533035e-06,
      "loss": 0.2213,
      "step": 14800
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9263636363636364,
      "eval_loss": 0.20984405279159546,
      "eval_runtime": 21.8169,
      "eval_samples_per_second": 605.034,
      "eval_steps_per_second": 2.383,
      "step": 14856
    }
  ],
  "logging_steps": 100,
  "max_steps": 22284,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 12,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7068206645899136e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
